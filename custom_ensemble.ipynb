{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iNSfD_CNspHJ"
      },
      "source": [
        "# Custom Bagging Application"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sPmhpzcWOpLV"
      },
      "source": [
        "### *Standard classification and aggregation methods*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c9iIAgW0OxgY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer, load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SIJ1OP4JNa8O"
      },
      "outputs": [],
      "source": [
        "#import data \n",
        "data = load_breast_cancer()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (455, 30)\n",
            "X_test shape: (114, 30)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qjb6z-lzagjQ"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08hBGDoiOr5C",
        "outputId": "55f73deb-34f3-4a46-b094-45bba5d08b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    0   1\n",
            "0  45   2\n",
            "1   2  65\n",
            "Accuracy: 0.9649122807017544\n",
            "f1_score: 0.9649122807017544\n"
          ]
        }
      ],
      "source": [
        "#logistic regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(pd.DataFrame(cm))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"f1_score: {f1_score(y_test, y_pred, average='weighted')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uEkMH7VOr2t",
        "outputId": "1222fd54-2582-4fce-f887-04600ce720a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    0   1\n",
            "0  44   3\n",
            "1   2  65\n",
            "Accuracy: 0.956140350877193\n",
            "f1_score: 0.9560669894569158\n"
          ]
        }
      ],
      "source": [
        "# AdaBoost with 7 logistic regression base learner experts and compare results.\n",
        "ada = AdaBoostClassifier(n_estimators=7, random_state=0, estimator = logreg)\n",
        "ada.fit(X_train, y_train)\n",
        "y_pred = ada.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(pd.DataFrame(cm))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"f1_score: {f1_score(y_test, y_pred, average='weighted')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dXBL62xQLGf",
        "outputId": "1f754dff-318b-4e4a-a99c-17d5969f4892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    0   1\n",
            "0  41   6\n",
            "1   0  67\n",
            "Accuracy: 0.9473684210526315\n",
            "f1_score: 0.9467019822282979\n",
            "    0   1\n",
            "0  44   3\n",
            "1   2  65\n",
            "Accuracy: 0.956140350877193\n",
            "f1_score: 0.9560669894569158\n"
          ]
        }
      ],
      "source": [
        "ada = AdaBoostClassifier(n_estimators=3, random_state=0, estimator = logreg)\n",
        "ada.fit(X_train, y_train)\n",
        "y_pred = ada.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(pd.DataFrame(cm))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"f1_score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
        "\n",
        "ada = AdaBoostClassifier(n_estimators=10, random_state=0, estimator = logreg)\n",
        "ada.fit(X_train, y_train)\n",
        "y_pred = ada.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(pd.DataFrame(cm))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"f1_score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
        "\n",
        "#10 is better "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd-CRutKOsSR"
      },
      "source": [
        "### *Custom-made Ensemble model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "1m8pqRbwOtZE",
        "outputId": "c3e16226-dea0-4a67-a2ed-8eb006d36fb9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>...</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>...</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>...</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>...</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>...</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>...</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>...</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0           1           2            3           4   \\\n",
              "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
              "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
              "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
              "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
              "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
              "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
              "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
              "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
              "\n",
              "               5           6           7           8           9   ...  \\\n",
              "count  569.000000  569.000000  569.000000  569.000000  569.000000  ...   \n",
              "mean     0.104341    0.088799    0.048919    0.181162    0.062798  ...   \n",
              "std      0.052813    0.079720    0.038803    0.027414    0.007060  ...   \n",
              "min      0.019380    0.000000    0.000000    0.106000    0.049960  ...   \n",
              "25%      0.064920    0.029560    0.020310    0.161900    0.057700  ...   \n",
              "50%      0.092630    0.061540    0.033500    0.179200    0.061540  ...   \n",
              "75%      0.130400    0.130700    0.074000    0.195700    0.066120  ...   \n",
              "max      0.345400    0.426800    0.201200    0.304000    0.097440  ...   \n",
              "\n",
              "               20          21          22           23          24  \\\n",
              "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
              "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
              "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
              "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
              "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
              "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
              "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
              "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
              "\n",
              "               25          26          27          28          29  \n",
              "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
              "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
              "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
              "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
              "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
              "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
              "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
              "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import SVC, KNN\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "dataa = pd.DataFrame(data.data)\n",
        "dataa.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "tVCoqzfCTlLY",
        "outputId": "c7e70d41-8647-4564-f0c4-7a0a0ad9cb90"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0      1       2       3        4        5       6        7       8   \\\n",
              "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
              "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
              "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
              "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
              "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
              "\n",
              "        9   ...     20     21      22      23      24      25      26      27  \\\n",
              "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
              "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
              "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
              "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
              "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
              "\n",
              "       28       29  \n",
              "0  0.4601  0.11890  \n",
              "1  0.2750  0.08902  \n",
              "2  0.3613  0.08758  \n",
              "3  0.6638  0.17300  \n",
              "4  0.2364  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataa.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmvvYuzsOumd",
        "outputId": "2abb9d00-0253-48cb-f5eb-38394a4c2a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (455, 30), y_train: (455,)\n",
            "X_val: (57, 30), y_val: (57,)\n",
            "X_test: (57, 30), y_test: (57,)\n",
            "\n",
            "Sample point: [1.268e+01 2.384e+01 8.269e+01 4.990e+02 1.122e-01 1.262e-01 1.128e-01\n",
            " 6.873e-02 1.905e-01 6.590e-02 4.255e-01 1.178e+00 2.927e+00 3.646e+01\n",
            " 7.781e-03 2.648e-02 2.973e-02 1.290e-02 1.635e-02 3.601e-03 1.709e+01\n",
            " 3.347e+01 1.118e+02 8.883e+02 1.851e-01 4.061e-01 4.024e-01 1.716e-01\n",
            " 3.383e-01 1.031e-01] → 0\n"
          ]
        }
      ],
      "source": [
        "def train_val_test_split(x, y):\n",
        "    X_train, X_, y_train, y_ = train_test_split(x, y, train_size=0.8)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(data.data, data.target)\n",
        "\n",
        "\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\\n\")\n",
        "\n",
        "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aaPa5O0HOuko"
      },
      "outputs": [],
      "source": [
        "scaled_X_train = StandardScaler().fit_transform(X_train)\n",
        "scaled_X_val = StandardScaler().fit_transform(X_val)\n",
        "scaled_X_test = StandardScaler().fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WNuThk9TbP4L"
      },
      "outputs": [],
      "source": [
        "#define a softmax function using just numpy that takes a vector as input and returns a vector of probabilities\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rFlncCBkOufq"
      },
      "outputs": [],
      "source": [
        "class Ensembler():\n",
        "    def __init__(self): \n",
        "        self.clf_gini = DecisionTreeClassifier(random_state=0, criterion='gini')\n",
        "        self.clf_entropy = DecisionTreeClassifier(random_state=0, criterion='entropy')\n",
        "        self.clf_rbf = SVC(random_state=0, kernel='rbf')\n",
        "        self.clf_poly = SVC(random_state=0, kernel='poly', degree=3)\n",
        "        self.clf_logreg = LogisticRegression(random_state=0)\n",
        "        self.clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "        self.weights = np.array([0, 0, 0, 0, 0, 0]) #initialise weights\n",
        "\n",
        "\n",
        "    def fit(self, X_train, X_test, y_train, y_test):\n",
        "        self.clf_gini.fit(X_train, y_train)\n",
        "        self.clf_entropy.fit(X_train, y_train)\n",
        "        self.clf_rbf.fit(X_train, y_train)\n",
        "        self.clf_poly.fit(X_train, y_train)\n",
        "        self.clf_logreg.fit(X_train, y_train)\n",
        "        self.clf_knn.fit(X_train, y_train)\n",
        "\n",
        "        #make predictions \n",
        "        y_pred_gini = self.clf_gini.predict(X_test)\n",
        "        y_pred_entropy = self.clf_entropy.predict(X_test)\n",
        "        y_pred_rbf = self.clf_rbf.predict(X_test)\n",
        "        y_pred_poly = self.clf_poly.predict(X_test)\n",
        "        y_pred_logreg = self.clf_logreg.predict(X_test)\n",
        "        y_pred_knn = self.clf_knn.predict(X_test)\n",
        "        preds = [y_pred_gini, y_pred_entropy, y_pred_rbf, y_pred_poly, y_pred_logreg, y_pred_knn]\n",
        "\n",
        "        #calculate accuracies of experts\n",
        "        accs = []\n",
        "        for clf in (self.clf_gini, self.clf_entropy, self.clf_rbf, self.clf_poly, self.clf_logreg, self.clf_knn):\n",
        "            accs.append(accuracy_score(y_test, clf.predict(X_test)))\n",
        "        print(f\"Accuracies: {accs}\")\n",
        "        \n",
        "        #update weights\n",
        "        self.weights = softmax(accs)\n",
        "        print(f\"Weights: {self.weights}\")\n",
        "\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        y_pred_gini = self.clf_gini.predict(X_test)\n",
        "        y_pred_entropy = self.clf_entropy.predict(X_test)\n",
        "        y_pred_rbf = self.clf_rbf.predict(X_test)\n",
        "        y_pred_poly = self.clf_poly.predict(X_test)\n",
        "        y_pred_logreg = self.clf_logreg.predict(X_test)\n",
        "        y_pred_knn = self.clf_knn.predict(X_test)\n",
        "        preds = [y_pred_gini, y_pred_entropy, y_pred_rbf, y_pred_poly, y_pred_logreg, y_pred_knn]\n",
        "        print(f\"Individual expert predictions: {preds}\\n\")\n",
        "\n",
        "        #get the weighted average of the predictions\n",
        "        w_preds = np.average(preds, axis=0, weights=self.weights)\n",
        "        print(f\"Weighted predictions: {w_preds}\\n\")\n",
        "        print(f\"Rounded weighted predictions: {np.round(w_preds)}\")\n",
        "        return w_preds.round()\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PBiX8VSnatmb"
      },
      "outputs": [],
      "source": [
        "ens = Ensembler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-EdJmqkatkG",
        "outputId": "4057aa7d-a916-436d-9128-c04bd29215b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracies: [0.8596491228070176, 0.8421052631578947, 0.8771929824561403, 0.9298245614035088, 0.8771929824561403, 0.8771929824561403]\n",
            "Weights: [0.16370895 0.16086191 0.16660638 0.17561    0.16660638 0.16660638]\n"
          ]
        }
      ],
      "source": [
        "ens.fit(scaled_X_train, scaled_X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZDrFSA6a2Qd",
        "outputId": "fedfe40e-3aac-4f1a-df9f-634ca61ef584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Individual expert predictions: [array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
            "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
            "       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0]), array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
            "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
            "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]), array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
            "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
            "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]), array([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
            "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
            "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]), array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
            "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
            "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]), array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
            "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
            "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0])]\n",
            "\n",
            "Weighted predictions: [1.         0.         0.17561    1.         0.         1.\n",
            " 0.         1.         1.         0.83913809 0.         0.\n",
            " 1.         1.         0.         1.         0.         1.\n",
            " 1.         1.         1.         0.         0.         1.\n",
            " 0.         1.         1.         0.         0.         1.\n",
            " 0.16370895 0.83913809 1.         1.         0.16660638 1.\n",
            " 1.         1.         0.16660638 0.17561    0.         1.\n",
            " 0.         1.         0.         1.         1.         1.\n",
            " 0.83629105 0.83629105 1.         0.         1.         0.\n",
            " 1.         1.         0.        ]\n",
            "\n",
            "Rounded weighted predictions: [1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 1. 0.]\n"
          ]
        }
      ],
      "source": [
        "final_preds = ens.predict(scaled_X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NvopCbODix3s"
      },
      "outputs": [],
      "source": [
        "final_acc = accuracy_score(y_val, final_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHPrmComkW9W",
        "outputId": "d6359bac-94f0-41da-d0dd-51c55b8ebc1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    0   1\n",
            "0  23   2\n",
            "1   0  32 \n",
            "\n",
            "Final accuracy: 96.49%\n",
            "Final f1_score: 96.47%\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(y_val, final_preds)\n",
        "print(pd.DataFrame(cm), \"\\n\")\n",
        "print(f\"Final accuracy: {round(final_acc*100, 2)}%\")\n",
        "print(f\"Final f1_score: {round(f1_score(y_val, final_preds, average='weighted')*100, 2)}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "57dbe44eb74a19d18f388e4d9fafc4d32a78d1722d572d14a517bc61ad3dae60"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
